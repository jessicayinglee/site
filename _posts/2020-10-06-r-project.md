---
layout: post
title: "Exploration of Incidence Rates for Disability Insurance Claims"
subtitle: "Language: R"
date: 2020-10-06
categories: projects
---

This project explores a proprietary dataset that contains over a million rows of administrative data from almost all major insurance carriers. As this is proprietary data, results have been masked. 

The variable of interest $$Y$$ is a binary variable representing whether the person is currently on disability insurance. If $$Y=1$$, the person has an active disability claim. Otherwise, $$Y=0$$; these observations are referred to as "exposure". 

# Setup
Packages, settings, and data import are in the code below.
```r
### SETUP ---------------------------------------------------
### General
library(magrittr)       # extend R syntax with %>% notation
library(tidyverse)      # data manipulation
library(stringr)        # string manipulation
library(skimr)          # data summaries
library(knitr)          # rendering R objects into Markdown

### Plotting
library(ggcorrplot)     # correlation plots for ggplot2
library(gridExtra)      # arranging multiple plots for ggplot2

### Statistics
library(caret)          # partition data
library(sandwich)       # gets heteroskedastic standard errors from regression
library(logistf)        # penalized logistic regressions
library(glmnet)         # ridge regression
library(pracma)         # for matrix algebra 

### Settings
options(scipen = 999)   # removes scientific notation for small numbers

### Import data
# Data was compiled into "incidence.csv" from the raw source files using Python.
data.initial <- read.csv("~/incidence.csv",
           na.strings = c(""),
           stringsAsFactors = T)
```

# Data Summary
Summaries were created using the `skimr` package, and were printed using the `kable` package. The following functions were used:
* `mySummary` creates a table with all the summary statistics of interest for a given dataset
* `kableIncidence` prints the incidence rate (claims divided by exposure) from a given `mySummary` table
* `mySkim` customizes the `skimr` summary function 

```r
### DATA SUMMARY ------------------------------------------------
### Create overall summary of dataset
mySummary <- function(data, y) {
  require(magrittr)
  n <- dim(data)[1]
  v <- dim(data)[2]
  c <- sum(y)
  e <- n - c
  labels <- c("Number of Observations",
              "Number of Variables",
              "Claims",
              "Exposure")
  output <- data.frame(labels, c(n, v, c, e))
  colnames(output) <- c("Summary", "Values")
  return(output)
}
kableIncidence <- function(summary){
  tibble(Incidence = summary[3,2] / summary[1,2]) %>% kable(digits = 4)
}
data.initial.summary <- mySummary(data.initial, data.initial$claim)

### Create summary of variables using package skimr
# Define summary statistics (skimmers)
base.skimmers <- sfl(missing_values = n_missing)

skimList <- function(x) {
  levels <- levels(x)
  paste0(levels, collapse = ", ")
}

factor.skimmers <- sfl(
  n_unique = "n_unique",
  categories = skimList,
  ordered = NULL,
  top_counts = NULL
)

numeric.skimmers <- sfl(hist = NULL)

# Compile the skimming function
mySkim <- skim_with(numeric = numeric.skimmers,
                    base = base.skimmers,
                    factor = factor.skimmers)

# Need industry to be numeric for later processing
# For summary purposes replace it with a factor
data.initial.industryfactor <-
  mutate(data.initial, NAISC = as.factor(NAISC))
data.initial.skim <- mySkim(data.initial.industryfactor)
```
## Overall Summary
```r
# Overall summary
kable(data.initial.summary,
      digits = 0,
      format.args = list(big.mark = ","))
kableIncidence(data.initial.summary)
```

## Factor Variable Summary
```r
# Factor variable summary
data.initial.skim.factor <- yank(data.initial.skim, "factor")
colnames(data.initial.skim.factor) <- data.initial.skim.factor %>%
  colnames() %>%
  str_replace("_", " ") %>%
  str_to_title()
kable(data.initial.skim.factor)
```

## Numeric Variable Summary
```r
# Numeric variable summary
data.initial.skim.numeric <- yank(data.initial.skim, "numeric")
colnames(data.initial.skim.numeric) <- data.initial.skim.numeric %>%
  colnames() %>%
  str_replace("_", " ") %>%
  str_to_title()
colnames(data.initial.skim.numeric)[5:9] <-
  c("Min", "1st Qu.", "Median", "3rd Qu.", "Max")
kable(data.initial.skim.numeric, digits = 2)
```

From the summaries, there are several issues with the data that need to be cleaned:
* Missing values
* Age ranges from 0 to 111
* Invalid region codes
* Invalid industry codes

# Data Cleaning
## Missing Values
There 46 rows with missing values, which all have $$ Y = 0 $$ and missing values in every other columns. These rows were dropped.
```r
# Retrieve rows with missing values
data.na <- subset(data.initial, rowSums(is.na(data.initial)) > 0)
kable(data.na[-1] %>% head %>% as_tibble(), 
      col.names = c("Province","Gender","Benefit","Age","Claim"),
      align = "l")
# Remove these 46 rows. Small amount, and all have Y=0 and other columns = NA
data <- subset(data.initial, rowSums(is.na(data.initial)) == 0)
```

## Age
Looking at the tail ends of the age distribution, there are unexpected data at the minimum and maximum: age = 0 and age = 111. The people of interest in this study are those in the working-age population. As a result, rows with age over 64 or under 16 will be removed.

18 exposure ($$ Y = 0 $$) and 2 claim ($$ Y = 1 $$) rows were removed for ages under 16, and 2186 exposure and 287 claim rows were removed for ages over 64.
```r
# Before starting, rename variables for convenience
colnames(data) <- str_to_lower(colnames(data)) %>%
  str_replace("province", "prov") %>%
  str_replace("benefit", "ben")

age.freq <- with(data, table(age, claim))

# Tail ends of age distribution
age.freq.low <- age.freq[as.numeric(rownames(age.freq)) < 16, ] %>%
  rbind(Total = age.freq[as.numeric(rownames(age.freq)) < 16, ] %>% colSums())
kable(tibble(Age = labels(age.freq.low)[[1]], 
                Exposure = age.freq.low[,1],
                Claims = age.freq.low[,2]))
age.freq.high <- age.freq[as.numeric(rownames(age.freq)) > 64, ] %>%
  rbind(Total = age.freq[as.numeric(rownames(age.freq)) > 64, ] %>% colSums())
kable(tibble(Age = labels(age.freq.high)[[1]], 
                Exposure = age.freq.high[,1],
                Claims = age.freq.high[,2]) %>% tail)

# Set min and max for age, removing extreme data
# Removed 2186 Y=0 and 287 Y=1 for age > 64
# Removed 18 Y=0 and 2 Y=1 for age < 16
age.min <- 16
age.max <- 64
data <- subset(data, (age > age.min & age < age.max))
```

## Region
```r
prov.freq <- with(data, table(prov, claim))
prov.freq.bad <- prov.freq[rownames(prov.freq) %in% c("RC", "XX"), ]
kable(tibble(Province = labels(prov.freq)[[1]], 
                Exposure = prov.freq[,1],
                Claims = prov.freq[,2]))
# Remove 30 Y=0 and 4 Y=1 rows with Provinces RC and XX, map to ROC/QC
data <- subset(data, (prov != "RC" & prov != "XX")) %>%
  mutate(region = factor(ifelse(prov == "QC", "QC", "ROC"),
                         levels = c("ROC", "QC")))
```

## Industry
Due to lack of observations in some industries as well as the notion that some industries will behave similarly in terms of incidence rates, standard NAISC industry codes have been mapped as follows:
* Blue Collar: codes 11, 21, 22, 23, 31, 33, 56
* Trade & Services: codes 41, 44, 48, 71, 72, 81
* White Collar: codes 51, 52, 53, 54, 55
* Public Services: codes 61, 62, 63, 91

The nonstandard industry codes (96 to 99) remain as-is, due to observed correlation between these codes and their incidence rates. This is discussed in the Data Exploration section for Industry.

```r
naisc.freq <- with(data, table(naisc, claim))

# Condense categories based on similarities for better prediction
industry.levels <- c(
  "BlueCollar",
  "TradeAndServices",
  "WhiteCollar",
  "PublicServices",
  "Invalid",
  "Missing",
  "Unmappable",
  "Unknown"
)

industryMapping <- function(x, levels) {
  require(magrittr)
  bc <- c(11, 21, 22, 23, 31, 33, 56)
  ts <- c(41, 44, 48, 71, 72, 81)
  wc <- c(51, 52, 53, 54, 55)
  ps <- c(61, 62, 63, 91)
  y <- case_when(
    x %in% bc ~ levels[1],
    x %in% ts ~ levels[2],
    x %in% wc ~ levels[3],
    x %in% ps ~ levels[4],
    x == 96 ~ levels[5],
    x == 97 ~ levels[6],
    x == 98 ~ levels[7],
    x == 99 ~ levels[8]
  ) %>%
    factor(levels = levels)
  return(y)
}

data$industry <- industryMapping(data$naisc, industry.levels)
```

## Resummarize

```r
# Summary ----------------------------------------------------------
# Summarize dataset
data[,c("naisc", "prov")] <- NULL
data.summary <- mySummary(data, data$claim)
kable(data.summary,
      digits = 2,
      format.args = list(big.mark = ","))
kableIncidence(data.summary)

# Summarize factor variables
data.skim <- mySkim(data)
data.skim.factor <- yank(data.skim, "factor")
colnames(data.skim.factor) <- data.skim.factor %>%
  colnames() %>%
  str_replace("_", " ") %>%
  str_to_title()
kable(data.skim.factor)

# Summarize numeric variables
data.skim.numeric <- yank(data.skim, "numeric")
colnames(data.skim.numeric) <- data.skim.numeric %>%
  colnames() %>%
  str_replace("_", " ") %>%
  str_to_title()
colnames(data.skim.numeric)[5:9] <-
  c("Min", "1st Qu.", "Median", "3rd Qu.", "Max")
kable(data.skim.numeric, digits = 2)
```


