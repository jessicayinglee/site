---
layout: post
title: "Exploration of Incidence Rates for Disability Insurance Claims"
subtitle: "Language: R"
date: 2020-10-06
categories: projects
mathjax: true
---

This project explores a proprietary dataset that contains over a million rows of administrative data from almost all major insurance carriers. As this is proprietary data, results have been masked. 

The variable of interest $$Y_i$$ is a binary variable representing whether the person is currently on disability insurance. If $$Y_i=1$$, then person $$i$$ has an active disability claim. Otherwise, $$Y_i=0$$; these observations are referred to as "exposure". 

# Setup
Packages, settings, and data import are in the code below.
```r
### SETUP ---------------------------------------------------
### General
library(magrittr)       # extend R syntax with %>% notation
library(tidyverse)      # data manipulation
library(stringr)        # string manipulation
library(skimr)          # data summaries
library(knitr)          # rendering R objects into Markdown

### Plotting
library(ggcorrplot)     # correlation plots for ggplot2
library(gridExtra)      # arranging multiple plots for ggplot2

### Statistics
library(caret)          # partition data
library(sandwich)       # gets heteroskedastic standard errors from regression
library(logistf)        # penalized logistic regressions
library(glmnet)         # ridge regression
library(pracma)         # for matrix algebra 

### Settings
options(scipen = 999)   # removes scientific notation for small numbers

### Import data
# Data was compiled into "incidence.csv" from the raw source files using Python.
data.initial <- read.csv("~/incidence.csv",
           na.strings = c(""),
           stringsAsFactors = T)
```

# Data Summary
Summaries were created using the `skimr` package, and were printed using the `kable` package. The following functions were used:
* `mySummary` creates a table with all the summary statistics of interest for a given dataset
* `kableIncidence` prints the incidence rate (claims divided by exposure) from a given `mySummary` table
* `mySkim` customizes the `skimr` summary function 

```r
### DATA SUMMARY ------------------------------------------------
### Create overall summary of dataset
mySummary <- function(data, y) {
  require(magrittr)
  n <- dim(data)[1]
  v <- dim(data)[2]
  c <- sum(y)
  e <- n - c
  labels <- c("Number of Observations",
              "Number of Variables",
              "Claims",
              "Exposure")
  output <- data.frame(labels, c(n, v, c, e))
  colnames(output) <- c("Summary", "Values")
  return(output)
}
kableIncidence <- function(summary){
  tibble(Incidence = summary[3,2] / summary[1,2]) %>% kable(digits = 4)
}
data.initial.summary <- mySummary(data.initial, data.initial$claim)

### Create summary of variables using package skimr
# Define summary statistics (skimmers)
base.skimmers <- sfl(missing_values = n_missing)

skimList <- function(x) {
  levels <- levels(x)
  paste0(levels, collapse = ", ")
}

factor.skimmers <- sfl(
  n_unique = "n_unique",
  categories = skimList,
  ordered = NULL,
  top_counts = NULL
)

numeric.skimmers <- sfl(hist = NULL)

# Compile the skimming function
mySkim <- skim_with(numeric = numeric.skimmers,
                    base = base.skimmers,
                    factor = factor.skimmers)

# Need industry to be numeric for later processing
# For summary purposes replace it with a factor
data.initial.industryfactor <-
  mutate(data.initial, NAISC = as.factor(NAISC))
data.initial.skim <- mySkim(data.initial.industryfactor)
```
## Overall Summary
```r
# Overall summary
kable(data.initial.summary,
      digits = 0,
      format.args = list(big.mark = ","))
kableIncidence(data.initial.summary)
```

## Factor Variable Summary
```r
# Factor variable summary
data.initial.skim.factor <- yank(data.initial.skim, "factor")
colnames(data.initial.skim.factor) <- data.initial.skim.factor %>%
  colnames() %>%
  str_replace("_", " ") %>%
  str_to_title()
kable(data.initial.skim.factor)
```

## Numeric Variable Summary
```r
# Numeric variable summary
data.initial.skim.numeric <- yank(data.initial.skim, "numeric")
colnames(data.initial.skim.numeric) <- data.initial.skim.numeric %>%
  colnames() %>%
  str_replace("_", " ") %>%
  str_to_title()
colnames(data.initial.skim.numeric)[5:9] <-
  c("Min", "1st Qu.", "Median", "3rd Qu.", "Max")
kable(data.initial.skim.numeric, digits = 2)
```

From the summaries, there are several issues with the data that need to be cleaned:
* Missing values
* Age ranges from 0 to 111
* Invalid region codes
* Invalid industry codes

# Data Cleaning
## Missing Values
There 46 rows with missing values, which all have $$ Y_i = 0 $$ and missing values in every other columns. These rows were dropped.
```r
# Retrieve rows with missing values
data.na <- subset(data.initial, rowSums(is.na(data.initial)) > 0)
kable(data.na[-1] %>% head %>% as_tibble(), 
      col.names = c("Province","Gender","Benefit","Age","Claim"),
      align = "l")
# Remove these 46 rows. Small amount, and all have Y=0 and other columns = NA
data <- subset(data.initial, rowSums(is.na(data.initial)) == 0)
```

## Age
Looking at the tail ends of the age distribution, there are unexpected data with ages equal to 0 and 111, however there does not appear to be any pattern associated with those observations. Since the people of interest in this study are those in the working-age population, rows with age over 64 or under 16 will be removed.

18 exposure ($$ Y_i = 0 $$) and 2 claim ($$ Y_i = 1 $$) rows were removed for ages under 16, and 2186 exposure and 287 claim rows were removed for ages over 64.
```r
# Before starting, rename variables for convenience
colnames(data) <- str_to_lower(colnames(data)) %>%
  str_replace("province", "prov") %>%
  str_replace("benefit", "ben")

age.freq <- with(data, table(age, claim))

# Tail ends of age distribution
age.freq.low <- age.freq[as.numeric(rownames(age.freq)) < 16, ] %>%
  rbind(Total = age.freq[as.numeric(rownames(age.freq)) < 16, ] %>% colSums())
kable(tibble(Age = labels(age.freq.low)[[1]], 
                Exposure = age.freq.low[,1],
                Claims = age.freq.low[,2]))
age.freq.high <- age.freq[as.numeric(rownames(age.freq)) > 64, ] %>%
  rbind(Total = age.freq[as.numeric(rownames(age.freq)) > 64, ] %>% colSums())
kable(tibble(Age = labels(age.freq.high)[[1]], 
                Exposure = age.freq.high[,1],
                Claims = age.freq.high[,2]) %>% tail)

# Set min and max for age, removing extreme data
# Removed 2186 Y=0 and 287 Y=1 for age > 64
# Removed 18 Y=0 and 2 Y=1 for age < 16
age.min <- 16
age.max <- 64
data <- subset(data, (age > age.min & age < age.max))
```

## Region
34 nonstandard region codes "RC" and "XX" were removed, of which 30 had $$Y_i = 0 $$ and 4 had $$ Y_i = 1 $$.
```r
prov.freq <- with(data, table(prov, claim))
prov.freq.bad <- prov.freq[rownames(prov.freq) %in% c("RC", "XX"), ]
kable(tibble(Province = labels(prov.freq)[[1]], 
                Exposure = prov.freq[,1],
                Claims = prov.freq[,2]))
# Remove 30 Y=0 and 4 Y=1 rows with Provinces RC and XX, map to ROC/QC
data <- subset(data, (prov != "RC" & prov != "XX")) %>%
  mutate(region = factor(ifelse(prov == "QC", "QC", "ROC"),
                         levels = c("ROC", "QC")))
```

## Industry
Due to lack of observations in some industries as well as the notion that some industries will behave similarly in terms of incidence rates, standard NAISC industry codes have been mapped as follows:
* Blue Collar: codes 11, 21, 22, 23, 31, 33, 56
* Trade & Services: codes 41, 44, 48, 71, 72, 81
* White Collar: codes 51, 52, 53, 54, 55
* Public Services: codes 61, 62, 63, 91

The nonstandard industry codes (96 to 99) remain as-is, due to observed correlation between these codes and their incidence rates. This is discussed in the Data Exploration section for Industry.

```r
naisc.freq <- with(data, table(naisc, claim))

# Condense categories based on similarities for better prediction
industry.levels <- c(
  "BlueCollar",
  "TradeAndServices",
  "WhiteCollar",
  "PublicServices",
  "Invalid",
  "Missing",
  "Unmappable",
  "Unknown"
)

industryMapping <- function(x, levels) {
  require(magrittr)
  bc <- c(11, 21, 22, 23, 31, 33, 56)
  ts <- c(41, 44, 48, 71, 72, 81)
  wc <- c(51, 52, 53, 54, 55)
  ps <- c(61, 62, 63, 91)
  y <- case_when(
    x %in% bc ~ levels[1],
    x %in% ts ~ levels[2],
    x %in% wc ~ levels[3],
    x %in% ps ~ levels[4],
    x == 96 ~ levels[5],
    x == 97 ~ levels[6],
    x == 98 ~ levels[7],
    x == 99 ~ levels[8]
  ) %>%
    factor(levels = levels)
  return(y)
}

data$industry <- industryMapping(data$naisc, industry.levels)
```

## Resummarize
The final summary of the dataset is below. 
```r
# Summary ----------------------------------------------------------
# Summarize dataset
data[,c("naisc", "prov")] <- NULL
data.summary <- mySummary(data, data$claim)
kable(data.summary,
      digits = 2,
      format.args = list(big.mark = ","))
kableIncidence(data.summary)

# Summarize factor variables
data.skim <- mySkim(data)
data.skim.factor <- yank(data.skim, "factor")
colnames(data.skim.factor) <- data.skim.factor %>%
  colnames() %>%
  str_replace("_", " ") %>%
  str_to_title()
kable(data.skim.factor)

# Summarize numeric variables
data.skim.numeric <- yank(data.skim, "numeric")
colnames(data.skim.numeric) <- data.skim.numeric %>%
  colnames() %>%
  str_replace("_", " ") %>%
  str_to_title()
colnames(data.skim.numeric)[5:9] <-
  c("Min", "1st Qu.", "Median", "3rd Qu.", "Max")
kable(data.skim.numeric, digits = 2)
```

# Data Exploration
This section tabulates and visualizes the data in order to recognize patterns and potential issues. Since the dependent variable is binary, graphs will plot the incidence rate (probability of $$ Y_i = 0 $$) on the y-axis. For categorical independent variables, graphs will have age on the x-axis and separate sets of points for each category. Age was chosen as it is known to be a strong predictor of disability incidence rates.  

To faciliate tabulation and plotting, the following functions are used:
```r
plotIncidence <- function(data, x, y, ...) {
  require(magrittr)
  require(ggplot2)
  x.name <- deparse(substitute(x))
  y.name <- deparse(substitute(y))
  x <- data[[x.name]]
  y <- data[[y.name]]
  index <- sort(unique(x))
  plot <- prop.table(table(x, y), 1)[, 2] %>%
    as.data.frame() %>%
    cbind(index) %>%
    setNames(c("incidence", x.name)) %>%
    ggplot(aes(x = index, y = incidence)) +
    geom_point() +
    labs(
      ...,
      subtitle = paste(
        "Exposure =",
        as.character(dim(data)[1] - sum(y)),
        ", Claims = ",
        as.character(sum(y))
      ),
      x = str_to_title(x.name),
      y = "Incidence"
    ) +
    theme_light() +
    scale_x_continuous(expand = c(0, 0), limits = c(min(x) - 1, max(x) + 1))
  return(plot)
}
plotIncidence2 <- function(data, x1, x2, y, ..., palette) {
  # for three-way tabulation, where the third var (x2) is binary
  require(magrittr)
  require(ggplot2)
  x1.name <- deparse(substitute(x1))
  x2.name <- deparse(substitute(x2))
  y.name <- deparse(substitute(y))
  
  x1 <- data[[x1.name]]
  x2 <- data[[x2.name]]
  y <- data[[y.name]]
  
  probA <- prop.table(table(x1, x2, y), 1)[, 1, 2]
  probB <- prop.table(table(x1, x2, y), 1)[, 2, 2]
  
  
  x1.data <- c(rep(sort(unique(x1)), 2))
  y.data <- c(probA, probB)
  
  x2.levels <- levels(x2)
  x2.data <- c(rep(x2.levels[1], length(probA)),
               rep(x2.levels[2], length(probB)))
  
  prob <- data.frame(
    x1.name = c(rep(sort(unique(
      x1
    )), 2)),
    incidence = c(probA, probB),
    x2.name = c(rep(x2.levels[1], length(probA)),
                rep(x2.levels[2], length(probB)))
  )
  
  freq <- table(x2, y)
  subtitle <- str_c(
    x2.levels[1],
    ": Exposure = ",
    format(freq[1, 1], big.mark = ",", scientific = FALSE),
    ", Claims = ",
    format(freq[1, 2], big.mark = ",", scientific = FALSE),
    "\n",
    x2.levels[2],
    ": Exposure = ",
    format(freq[2, 1], big.mark = ",", scientific = FALSE),
    ", Claims = ",
    format(freq[2, 2], big.mark = ",", scientific = FALSE)
  )
  
  plot <-
    ggplot(prob, aes(x = x1.name, y = incidence, color = x2.name)) +
    geom_point() +
    labs(
      ...,
      x = str_to_title(x1.name),
      y = "Incidence",
      subtitle = subtitle,
      color = str_to_title(x2.name)
    ) +
    theme_light() +
    scale_color_manual(values = palette) +
    scale_x_continuous(expand = c(0, 0), limits = c(15, 65)) +
    scale_y_continuous(expand = c(0, 0), limits = c(0, max(y.data) * 1.05))
  return(plot)
}
```

## Age
```r
plotIncidence(data, age, claim, title = "Incidence by Age")
```

## Industry
```r
# Before deciding how to handle them, need to look for patterns
data.i <- subset(data, industry %in% industry.levels[5:8])
data.i.freq <- table(data.i$industry, data.i$claim)
plot.i <- plotIncidence(data.i, age, claim,
                        title = "Incidence by Age for Industry = 96 to 99")

# Code 96: Invalid code submitted
data.i.i <- subset(data, data$industry == "Invalid")
plot.i.i <- plotIncidence(data.i.i, age, claim,
                          title = "Incidence by Age for Industry = 96 (invalid code)")

data.i.mi <- subset(data, data$industry == "Missing")
plot.i.mi <- plotIncidence(data.i.mi, age, claim,
                           title = "Incidence by Age for Industry = 97 (missing code)")

data.i.um <- subset(data, data$industry == "Unmappable")
plot.i.um <- plotIncidence(data.i.um, age, claim,
                           title = "Incidence by Age for Industry = 98 (unmappable code)")

data.i.uk <- subset(data, industry == "Unknown")
plot.i.uk <- plotIncidence(data.i.uk, age, claim,
                           title = "Incidence by Age for Industry = 98 (unknown code)")

# Plots show there is an abnormally high correlation between these codes and incidence
plot.i
grid.arrange(plot.i.i, plot.i.mi, plot.i.um, plot.i.uk, nrow = 2)
```

```r
palette.g <- c("#e66a5c", "#36757d")
hist.g <-
  ggplot(data, aes(x = age, color = gender, fill = gender)) +
  geom_histogram(binwidth = 1,
                 alpha = 0.75,
                 position = "stack") +
  labs(
    title = "Distribution of Age by Gender",
    x = "Age",
    y = "Count",
    subtitle = str_c(
      levels(data$gender)[1],
      " Observations = ",
      format(
        table(data$gender)[1],
        big.mark = ",",
        scientific = FALSE
      ),
      ", ",
      levels(data$gender)[2],
      " Observations = ",
      format(
        table(data$gender)[2],
        big.mark = ",",
        scientific = FALSE
      )
    )
  ) +
  theme_light() +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) +
  scale_color_manual(values = palette.g) +
  scale_fill_manual(values = palette.g) +
  scale_x_continuous(expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0), limits = c(0, 40000))

plot.g <- plotIncidence2(data, age, gender, claim,
                         palette = palette.g,
                         title = "Incidence by Age and Gender")
```
## Region
```r
palette.r <- c("#E6B753", "#5D7D39")
hist.r <-
  ggplot(data, aes(x = age, color = region, fill = region)) +
  geom_histogram(binwidth = 1,
                 alpha = 0.75,
                 position = "stack") +
  labs(
    title = "Distribution of Age by Region",
    x = "Age",
    y = "Count",
    subtitle = str_c(
      levels(data$region)[1],
      " Observations = ",
      format(
        table(data$region)[1],
        big.mark = ",",
        scientific = FALSE
      ),
      ", ",
      levels(data$region)[2],
      " Observations = ",
      format(
        table(data$region)[2],
        big.mark = ",",
        scientific = FALSE
      )
    )
  ) +
  theme_light() +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) +
  scale_color_manual(values = palette.r) +
  scale_fill_manual(values = palette.r) +
  scale_x_continuous(expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0), limits = c(0, 40000))

plot.r <-
  plotIncidence2(data,
                 age,
                 region,
                 claim,
                 palette = rev(palette.r),
                 title = "Incidence by Age and Region")
```

## Region and Female
```r
data.f <- subset(data, data$gender == "F")
plot.f.r <- plotIncidence2(data.f,
                           age,
                           region,
                           claim,
                           palette = rev(palette.r),
                           title = "Female Incidence by Age and Region")
```

## Region and Male
```r
data.m <- subset(data, data$gender == "M")
plot.m.r <- plotIncidence2(data.m, 
                           age, 
                           region, 
                           claim,
                           palette = rev(palette.r),
                           title = "Male Incidence by Age and Region")
```

## Benefit Amount
```r
# Round benefit amounts to nearest 10 for plotting
hist.b <-
  ggplot(data, aes(x = ben, color = gender, fill = gender)) +
  geom_histogram(binwidth = 100,
                 alpha = 0.75,
                 position = "stack") +
  labs(
    title = "Distribution of Benefit Amount by Gender",
    x = "Benefit Amount",
    y = "Count",
    subtitle = str_c(
      levels(data$gender)[1],
      " Observations = ",
      format(
        table(data$gender)[1],
        big.mark = ",",
        scientific = FALSE
      ),
      ", ",
      levels(data$gender)[2],
      " Observations = ",
      format(
        table(data$gender)[2],
        big.mark = ",",
        scientific = FALSE
      )
    )
  ) +
  theme_light() +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) +
  scale_color_manual(values = palette.g) +
  scale_fill_manual(values = palette.g) +
  scale_x_continuous(expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0), limits = c(0, 40000))
hist.b

data.b <- mutate(data, ben = round(ben*2, -2)/2)
freq.b <- table(data.b$ben, data.b$claim)
plot.b <- plotIncidence(data.b, ben, claim, title = "Incidence by Benefit Amount") 
```
Benefit amounts show high variance under 1000 and after 5000. 
```{r}
plot.b <- plotIncidence(mutate(data, ben = round(ben*2, -2)/2), 
                        ben, claim, title = "Incidence by Benefit Amount") 
plot.b
```
Looking more closely, incidence rates by benefit amount seem to spike downwards when the benefit amount is a “nice” number. Incidence rates for smaller benefit amounts tended to spikes downwards at amounts divisible by 100. For larger amounts, these spikes tended to occur at amounts divisible by 500 and 1000.
```r
freq.b <- table(round(data$ben,-2)/2, data$claim)
freq.b.output <- 
  tibble(Benefit = labels(freq.b)[[1]], 
                Exposure = freq.b[,1],
                Claims = freq.b[,2]) %>% 
  mutate(Incidence = Claims/(Claims+Exposure))
kable(freq.b.output[27:37,], digits = c(0,0,0,4))
kable(freq.b.output[60:85,], digits = c(0,0,0,4))
```
Simultaneity is a potential issue with this data. It might be that benefit amounts are more exact when being reported for a claim. This affects the validity of model estimates and predictive ability.

# Initial Regression Analysis
The regressions run in this section are not intended to give an in-depth analysis of the data. The purpose of this study is moreso to explore the dataset. The data will only be partitioned once in a 67/33 split.

Furthermore, it is likely that the estimates are biased due to the low occurance of $$ Y_i = 0 $$; this is sometimes referred to as a "rare events" bias. There are several approaches to reducing this bias, generally by penalizing the log-likelihood function. Common methods include Firth's logistic regression, ridge and lasso regressions, and Bayes' GLM. Due to the size of the dataset and limited computational power, only the ridge regression was estimated. 

The ridge regression produces estimates with lower biases, at the cost of increasing their variances. A parameter $$ \lambda I $$ is added so that $$ \hat{\beta} = \left( X^T X + \lambda I \right)^{-1} X^T y $$. $$\lambda$$ is chosen to minimize a criterion; most commonly, it minimizes the cross-validated errors (CV).

Comparisons between models were made based on the AIC and the Brier Score (BS). The former emphasizes model fit and the latter emphasizes predictive ability. The Brier Score is essentially the mean-squared-error, $$\sum_i \left(Y_i - \overline{Y}\right)^2$$. Note that if we just blindly guessed the average incidence rate of 0.079 for each observation, then the BS would be 
\( (1 - 0.079)(0.079 - 0)^2 + (0.079)(0.079 - 1)^2 = 0.0728 \).

